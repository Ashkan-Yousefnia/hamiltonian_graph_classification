{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8960572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\albumentations\\__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.19 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from math import atan2, cos, sin, sqrt, pi, log\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as pathces\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F2\n",
    "from PIL import Image\n",
    "from numpy import linalg as LA\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import DataLoader, random_split,TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ae9b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading/Loading the dataset files\n",
    "# TODO\n",
    "train_set = pd.read_csv('train_info.csv')\n",
    "PATH = 'train_images\\\\'\n",
    "finalDimention = 128\n",
    "transform = transforms.Compose([ transforms.ToTensor(), # normalizes to range [0,1]\n",
    "                        transforms.Resize([finalDimention,finalDimention]),\n",
    "                        transforms.Grayscale()\n",
    "                       ])\n",
    "images = []\n",
    "labels = torch.zeros(len(train_set))\n",
    "for i in range(len(train_set)):\n",
    "    testIm = cv2.imread(PATH+train_set.file_name[i])\n",
    "    images.append(transform(testIm))   \n",
    "    if (train_set.hamiltonian[i]=='yes'):\n",
    "        labels[i] = 1\n",
    "    else:\n",
    "        labels[i] = 0\n",
    "img = Image.open(PATH+train_set.file_name[i]);\n",
    "\n",
    "\n",
    "# cnts = cv2.findContours(image.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# print(cnts)\n",
    "# seprate_image(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7f2530",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesT = torch.stack(images, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c9a153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0.,  ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd0d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data, train_labels,test_labels = train_test_split(imagesT, labels, test_size=0.2,shuffle=True)\n",
    "train_data = TensorDataset(train_data,train_labels)\n",
    "test_data  = TensorDataset(test_data,test_labels)\n",
    "\n",
    "# finally, translate into dataloader objects\n",
    "batchsize    = 8\n",
    "train_loader = DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)\n",
    "test_loader  = DataLoader(test_data,batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "082fa937",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels),\n",
    "                        nn.ReLU())\n",
    "        self.conv2 = nn.Sequential(\n",
    "                        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.BatchNorm2d(out_channels))\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a53d50b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTheNet(block, layers, num_classes = 4,printtoggle=False):\n",
    "\n",
    "  class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 4):\n",
    "      super(ResNet, self).__init__()\n",
    "\n",
    "      self.print = printtoggle\n",
    "\n",
    "      self.inplanes = 64\n",
    "      self.conv1 = nn.Sequential(\n",
    "                      nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                      nn.BatchNorm2d(64),\n",
    "                      nn.ReLU())\n",
    "      self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "      self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "      self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "      self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "      #self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "      self.avgpool = nn.AvgPool2d(3, stride=1)\n",
    "      self.fc1 = nn.Linear(9216, 256)\n",
    "      self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "      downsample = None\n",
    "      if stride != 1 or self.inplanes != planes:\n",
    "          downsample = nn.Sequential(\n",
    "              nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride),\n",
    "              nn.BatchNorm2d(planes),\n",
    "          )\n",
    "      layers = []\n",
    "      layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "      self.inplanes = planes\n",
    "      for i in range(1, blocks):\n",
    "          layers.append(block(self.inplanes, planes))\n",
    "      return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.conv1(x)\n",
    "      if self.print: print(f'First CPR block: {list(x.shape)}')\n",
    "      x = self.maxpool(x)\n",
    "      x = self.layer0(x)\n",
    "      if self.print: print(f'2 CPR block: {list(x.shape)}')\n",
    "      x = self.layer1(x)\n",
    "      x = F.dropout2d(x,p=.2)\n",
    "      if self.print: print(f'3 CPR block: {list(x.shape)}')\n",
    "      x = self.layer2(x)\n",
    "      if self.print: print(f'4 CPR block: {list(x.shape)}')\n",
    "      #x = self.layer3(x)\n",
    "      #if self.print: print(f'5 CPR block: {list(x.shape)}')\n",
    "      x = self.avgpool(x)\n",
    "      if self.print: print(f'avg block: {list(x.shape)}')\n",
    "      nUnits = x.shape.numel()/x.shape[0]\n",
    "      x = x.view(-1,int(nUnits))\n",
    "      if self.print: print(f'Vectorized: {list(x.shape)}')\n",
    "      x = self.fc1(x)\n",
    "      x = F.dropout(x,.4)\n",
    "      x = self.fc2(x)\n",
    "      return x\n",
    "\n",
    "  # create the model instance\n",
    "  net = ResNet(block, layers, num_classes)\n",
    "  lossfun = nn.BCEWithLogitsLoss()\n",
    "  # optimizer\n",
    "  optimizer = torch.optim.AdamW(net.parameters(),lr=.001)\n",
    "\n",
    "  return net,optimizer,lossfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da8702a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First CPR block: [8, 64, 64, 64]\n",
      "2 CPR block: [8, 64, 32, 32]\n",
      "3 CPR block: [8, 128, 16, 16]\n",
      "4 CPR block: [8, 256, 8, 8]\n",
      "avg block: [8, 256, 6, 6]\n",
      "Vectorized: [8, 9216]\n",
      "\n",
      "Output size:\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8])\n",
      " \n",
      "Loss:\n",
      "tensor(0.8945, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "net,optimizer,lossFun = makeTheNet(ResidualBlock, [3, 4, 6, 3],1,True)\n",
    "\n",
    "X,y = next(iter(train_loader))\n",
    "yHat = net(X)\n",
    "\n",
    "# check size of output\n",
    "print('\\nOutput size:')\n",
    "print(yHat.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# # now let's compute the loss\n",
    "#y = y[:,None]\n",
    "loss = lossFun(yHat.squeeze(),y)\n",
    "print(' ')\n",
    "print('Loss:')\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a08359",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fcfb2241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First CPR block: [2, 64, 64, 64]\n",
      "2 CPR block: [2, 64, 32, 32]\n",
      "3 CPR block: [2, 128, 16, 16]\n",
      "4 CPR block: [2, 256, 8, 8]\n",
      "avg block: [2, 256, 6, 6]\n",
      "Vectorized: [2, 9216]\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 64, 64]           3,200\n",
      "       BatchNorm2d-2           [-1, 64, 64, 64]             128\n",
      "              ReLU-3           [-1, 64, 64, 64]               0\n",
      "         MaxPool2d-4           [-1, 64, 32, 32]               0\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "              ReLU-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,928\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "             ReLU-10           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-11           [-1, 64, 32, 32]               0\n",
      "           Conv2d-12           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-13           [-1, 64, 32, 32]             128\n",
      "             ReLU-14           [-1, 64, 32, 32]               0\n",
      "           Conv2d-15           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-16           [-1, 64, 32, 32]             128\n",
      "             ReLU-17           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-18           [-1, 64, 32, 32]               0\n",
      "           Conv2d-19           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-20           [-1, 64, 32, 32]             128\n",
      "             ReLU-21           [-1, 64, 32, 32]               0\n",
      "           Conv2d-22           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-23           [-1, 64, 32, 32]             128\n",
      "             ReLU-24           [-1, 64, 32, 32]               0\n",
      "    ResidualBlock-25           [-1, 64, 32, 32]               0\n",
      "           Conv2d-26          [-1, 128, 16, 16]          73,856\n",
      "      BatchNorm2d-27          [-1, 128, 16, 16]             256\n",
      "             ReLU-28          [-1, 128, 16, 16]               0\n",
      "           Conv2d-29          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-30          [-1, 128, 16, 16]             256\n",
      "           Conv2d-31          [-1, 128, 16, 16]           8,320\n",
      "      BatchNorm2d-32          [-1, 128, 16, 16]             256\n",
      "             ReLU-33          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-34          [-1, 128, 16, 16]               0\n",
      "           Conv2d-35          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-36          [-1, 128, 16, 16]             256\n",
      "             ReLU-37          [-1, 128, 16, 16]               0\n",
      "           Conv2d-38          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-39          [-1, 128, 16, 16]             256\n",
      "             ReLU-40          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-41          [-1, 128, 16, 16]               0\n",
      "           Conv2d-42          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-43          [-1, 128, 16, 16]             256\n",
      "             ReLU-44          [-1, 128, 16, 16]               0\n",
      "           Conv2d-45          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-46          [-1, 128, 16, 16]             256\n",
      "             ReLU-47          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-48          [-1, 128, 16, 16]               0\n",
      "           Conv2d-49          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-50          [-1, 128, 16, 16]             256\n",
      "             ReLU-51          [-1, 128, 16, 16]               0\n",
      "           Conv2d-52          [-1, 128, 16, 16]         147,584\n",
      "      BatchNorm2d-53          [-1, 128, 16, 16]             256\n",
      "             ReLU-54          [-1, 128, 16, 16]               0\n",
      "    ResidualBlock-55          [-1, 128, 16, 16]               0\n",
      "           Conv2d-56            [-1, 256, 8, 8]         295,168\n",
      "      BatchNorm2d-57            [-1, 256, 8, 8]             512\n",
      "             ReLU-58            [-1, 256, 8, 8]               0\n",
      "           Conv2d-59            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-60            [-1, 256, 8, 8]             512\n",
      "           Conv2d-61            [-1, 256, 8, 8]          33,024\n",
      "      BatchNorm2d-62            [-1, 256, 8, 8]             512\n",
      "             ReLU-63            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-64            [-1, 256, 8, 8]               0\n",
      "           Conv2d-65            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-66            [-1, 256, 8, 8]             512\n",
      "             ReLU-67            [-1, 256, 8, 8]               0\n",
      "           Conv2d-68            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-69            [-1, 256, 8, 8]             512\n",
      "             ReLU-70            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-71            [-1, 256, 8, 8]               0\n",
      "           Conv2d-72            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-73            [-1, 256, 8, 8]             512\n",
      "             ReLU-74            [-1, 256, 8, 8]               0\n",
      "           Conv2d-75            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-76            [-1, 256, 8, 8]             512\n",
      "             ReLU-77            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-78            [-1, 256, 8, 8]               0\n",
      "           Conv2d-79            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-80            [-1, 256, 8, 8]             512\n",
      "             ReLU-81            [-1, 256, 8, 8]               0\n",
      "           Conv2d-82            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-83            [-1, 256, 8, 8]             512\n",
      "             ReLU-84            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-85            [-1, 256, 8, 8]               0\n",
      "           Conv2d-86            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-87            [-1, 256, 8, 8]             512\n",
      "             ReLU-88            [-1, 256, 8, 8]               0\n",
      "           Conv2d-89            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-90            [-1, 256, 8, 8]             512\n",
      "             ReLU-91            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-92            [-1, 256, 8, 8]               0\n",
      "           Conv2d-93            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-94            [-1, 256, 8, 8]             512\n",
      "             ReLU-95            [-1, 256, 8, 8]               0\n",
      "           Conv2d-96            [-1, 256, 8, 8]         590,080\n",
      "      BatchNorm2d-97            [-1, 256, 8, 8]             512\n",
      "             ReLU-98            [-1, 256, 8, 8]               0\n",
      "    ResidualBlock-99            [-1, 256, 8, 8]               0\n",
      "       AvgPool2d-100            [-1, 256, 6, 6]               0\n",
      "          Linear-101                  [-1, 512]       4,719,104\n",
      "          Linear-102                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 12,888,577\n",
      "Trainable params: 12,888,577\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 30.07\n",
      "Params size (MB): 49.17\n",
      "Estimated Total Size (MB): 79.30\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net.cpu(),(1,128,128),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb5fbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function2trainTheModel(trainLoader,testLoader):\n",
    "\n",
    "  # number of epochs\n",
    "  numepochs = 10\n",
    "  \n",
    "  # create a new model\n",
    "  net,optimizer,lossFun = makeTheNet(ResidualBlock, [3, 4, 6, 3],1)\n",
    "  best_valid_Err = 100000\n",
    "  # send the model to the GPU\n",
    "  net.to(device)\n",
    "\n",
    "  # initialize losses\n",
    "  trainLoss = torch.zeros(numepochs)\n",
    "  testLoss  = torch.zeros(numepochs)\n",
    "  trainErr  = torch.zeros(numepochs)\n",
    "  testErr   = torch.zeros(numepochs)\n",
    "\n",
    "\n",
    "  # loop over epochs\n",
    "  for epochi in range(numepochs):\n",
    "\n",
    "    # loop over training data batches\n",
    "    net.train()\n",
    "    batchLoss = []\n",
    "    batchErr  = []\n",
    "    \n",
    "    for step,batch in enumerate(trainLoader):\n",
    "      # push data to GPU\n",
    "      if step % 50 == 0 and not step == 0:\n",
    "        print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(trainLoader)))\n",
    "      X,y = batch\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      # forward pass and loss\n",
    "      yHat = net(X)\n",
    "      loss = lossFun(yHat.squeeze(),y)\n",
    "\n",
    "      # backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # loss and error from this batch\n",
    "      batchLoss.append(loss.item())\n",
    "      \n",
    "\n",
    "    # and get average losses and error rates across the batches\n",
    "    trainLoss[epochi] = np.mean(batchLoss)\n",
    "\n",
    "\n",
    "\n",
    "    ### test performance\n",
    "    net.eval()\n",
    "    batchAcc = []\n",
    "    print(f\"Eval. train loss {trainLoss[epochi]}\")\n",
    "    for X,y in testLoader:\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "      # forward pass and loss\n",
    "      with torch.no_grad():\n",
    "        yHat = net(X)\n",
    "\n",
    "\n",
    "    testErr[epochi]  = lossFun(yHat.squeeze(),y).item()\n",
    "\n",
    "    if testErr[epochi] < best_valid_Err:\n",
    "        best_valid_Err = testErr[epochi]\n",
    "        torch.save(net.state_dict(), 'saved_weights6.pt')\n",
    "    print(f'Finished epoch {epochi+1}/{numepochs}. Test Loss = {testErr[epochi]:.2f}')\n",
    "  # end epochs\n",
    "\n",
    "  # function output\n",
    "  return trainLoss,testLoss,testErr,net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb213301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 1.862845778465271\n",
      "Finished epoch 1/10. Test Loss = 1.23\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.433574378490448\n",
      "Finished epoch 2/10. Test Loss = 0.75\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.3309047520160675\n",
      "Finished epoch 3/10. Test Loss = 2.33\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.29497194290161133\n",
      "Finished epoch 4/10. Test Loss = 0.32\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.25281983613967896\n",
      "Finished epoch 5/10. Test Loss = 0.52\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.25829118490219116\n",
      "Finished epoch 6/10. Test Loss = 0.28\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.2463407665491104\n",
      "Finished epoch 7/10. Test Loss = 0.99\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.21384450793266296\n",
      "Finished epoch 8/10. Test Loss = 2.67\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.2012251913547516\n",
      "Finished epoch 9/10. Test Loss = 1.48\n",
      "  Batch    50  of    442.\n",
      "  Batch   100  of    442.\n",
      "  Batch   150  of    442.\n",
      "  Batch   200  of    442.\n",
      "  Batch   250  of    442.\n",
      "  Batch   300  of    442.\n",
      "  Batch   350  of    442.\n",
      "  Batch   400  of    442.\n",
      "Eval. train loss 0.19165584444999695\n",
      "Finished epoch 10/10. Test Loss = 2.77\n"
     ]
    }
   ],
   "source": [
    "trainLoss,testLoss,testErr,net = function2trainTheModel(train_loader,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226a2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,_,_ = makeTheNet(ResidualBlock, [3, 4, 6, 3],1)\n",
    "model.load_state_dict(torch.load('saved_weights6.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "257ca820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output size:\n",
      "tensor([[ 3.0474e+00],\n",
      "        [ 3.0799e+00],\n",
      "        [-5.3124e+00],\n",
      "        [-4.1741e+00],\n",
      "        [-5.2056e+00],\n",
      "        [ 2.5299e+00],\n",
      "        [-3.4927e+00],\n",
      "        [-1.3757e+00],\n",
      "        [-6.5969e+00],\n",
      "        [ 1.1118e+00],\n",
      "        [ 2.4990e+00],\n",
      "        [-7.3999e+00],\n",
      "        [ 2.6800e+00],\n",
      "        [-5.4704e+00],\n",
      "        [-5.9672e+00],\n",
      "        [-1.2815e+00],\n",
      "        [ 2.4400e+00],\n",
      "        [-1.5143e+00],\n",
      "        [-2.0816e+00],\n",
      "        [-6.0026e+00],\n",
      "        [-1.9072e+00],\n",
      "        [-4.3022e+00],\n",
      "        [ 4.1840e+00],\n",
      "        [-4.2486e+00],\n",
      "        [-6.9170e+00],\n",
      "        [-1.0978e+01],\n",
      "        [ 5.6878e-01],\n",
      "        [-5.8929e+00],\n",
      "        [ 4.6516e+00],\n",
      "        [ 4.7251e+00],\n",
      "        [ 1.0084e+00],\n",
      "        [ 2.4786e+00],\n",
      "        [-6.1533e-01],\n",
      "        [-3.1057e+00],\n",
      "        [-4.2302e+00],\n",
      "        [-4.9400e+00],\n",
      "        [ 4.9310e+00],\n",
      "        [-7.2308e+00],\n",
      "        [-6.6984e+00],\n",
      "        [-8.5905e+00],\n",
      "        [-5.9816e+00],\n",
      "        [-1.2586e+00],\n",
      "        [ 4.7628e+00],\n",
      "        [-4.0109e+00],\n",
      "        [ 5.2580e+00],\n",
      "        [-4.5902e+00],\n",
      "        [-5.9912e+00],\n",
      "        [ 3.7922e+00],\n",
      "        [-7.7741e+00],\n",
      "        [ 6.6284e+00],\n",
      "        [-4.7926e+00],\n",
      "        [ 4.9068e-01],\n",
      "        [ 4.0803e+00],\n",
      "        [-5.1062e+00],\n",
      "        [ 4.6793e+00],\n",
      "        [-1.5269e+00],\n",
      "        [-2.5096e+00],\n",
      "        [ 5.7131e+00],\n",
      "        [ 4.5869e+00],\n",
      "        [ 4.8205e+00],\n",
      "        [-2.5773e+00],\n",
      "        [-7.4164e+00],\n",
      "        [ 3.4455e+00],\n",
      "        [-1.3718e+00],\n",
      "        [-6.2016e+00],\n",
      "        [ 6.3421e+00],\n",
      "        [ 2.6703e+00],\n",
      "        [-2.8915e+00],\n",
      "        [ 5.2698e+00],\n",
      "        [ 5.9326e+00],\n",
      "        [ 2.9538e+00],\n",
      "        [ 1.7432e+00],\n",
      "        [-9.1226e+00],\n",
      "        [-4.7910e+00],\n",
      "        [-1.8456e+00],\n",
      "        [ 2.3127e+00],\n",
      "        [ 5.7599e+00],\n",
      "        [ 1.2359e+00],\n",
      "        [-1.0369e+01],\n",
      "        [ 9.5833e-01],\n",
      "        [ 1.1773e+00],\n",
      "        [-2.2113e+00],\n",
      "        [ 8.9455e-02],\n",
      "        [-2.1665e+00],\n",
      "        [-3.0986e+00],\n",
      "        [-3.1488e+00],\n",
      "        [-3.7493e+00],\n",
      "        [ 4.3362e+00],\n",
      "        [ 2.8993e+00],\n",
      "        [-1.2138e+00],\n",
      "        [ 7.5482e+00],\n",
      "        [-9.8096e+00],\n",
      "        [-7.1206e+00],\n",
      "        [-6.7863e+00],\n",
      "        [ 1.8226e+00],\n",
      "        [ 2.8832e+00],\n",
      "        [-4.6149e+00],\n",
      "        [-7.4030e+00],\n",
      "        [ 4.9419e+00],\n",
      "        [-1.1989e+01],\n",
      "        [-3.5118e+00],\n",
      "        [-6.9513e+00],\n",
      "        [ 3.6001e+00],\n",
      "        [ 4.9935e+00],\n",
      "        [-6.9376e+00],\n",
      "        [ 2.0965e+00],\n",
      "        [-6.8335e+00],\n",
      "        [-2.6724e+00],\n",
      "        [ 3.9977e+00],\n",
      "        [-6.7813e+00],\n",
      "        [-1.5544e+00],\n",
      "        [ 5.5751e+00],\n",
      "        [-4.7947e+00],\n",
      "        [-3.1801e+00],\n",
      "        [ 3.5618e+00],\n",
      "        [-1.6782e+00],\n",
      "        [-6.6043e+00],\n",
      "        [-8.2500e+00],\n",
      "        [ 4.3927e+00],\n",
      "        [-1.9807e+00],\n",
      "        [ 9.1598e-01],\n",
      "        [ 3.4903e+00],\n",
      "        [ 2.1943e+00],\n",
      "        [ 3.2076e+00],\n",
      "        [-7.6160e+00],\n",
      "        [-5.8473e+00],\n",
      "        [-1.5567e+00],\n",
      "        [ 1.3034e+00],\n",
      "        [ 5.5565e+00],\n",
      "        [-4.1687e+00],\n",
      "        [ 5.5366e+00],\n",
      "        [ 5.9754e+00],\n",
      "        [ 6.0166e+00],\n",
      "        [-9.4625e+00],\n",
      "        [-1.4029e+01],\n",
      "        [-5.6538e+00],\n",
      "        [-5.8407e+00],\n",
      "        [-6.9293e+00],\n",
      "        [-9.2639e+00],\n",
      "        [ 3.3564e+00],\n",
      "        [ 2.0905e+00],\n",
      "        [ 2.9960e+00],\n",
      "        [-6.9037e+00],\n",
      "        [ 5.1628e+00],\n",
      "        [ 1.7925e+00],\n",
      "        [-5.8227e+00],\n",
      "        [-1.3948e+00],\n",
      "        [ 5.1475e+00],\n",
      "        [ 2.3796e+00],\n",
      "        [ 2.4807e+00],\n",
      "        [ 2.9514e+00],\n",
      "        [ 5.3317e+00],\n",
      "        [ 5.3279e+00],\n",
      "        [ 3.7087e+00],\n",
      "        [ 6.4085e+00],\n",
      "        [ 4.2289e+00],\n",
      "        [-5.2958e+00],\n",
      "        [-9.3466e+00],\n",
      "        [-9.1665e+00],\n",
      "        [-1.2631e+00],\n",
      "        [-4.1024e+00],\n",
      "        [ 1.6489e+00],\n",
      "        [-4.8672e+00],\n",
      "        [-7.6110e-01],\n",
      "        [ 1.4539e+00],\n",
      "        [ 3.5126e+00],\n",
      "        [-5.9503e+00],\n",
      "        [-3.6833e+00],\n",
      "        [-3.4586e+00],\n",
      "        [-4.1957e+00],\n",
      "        [-1.3208e+01],\n",
      "        [ 3.1359e+00],\n",
      "        [-1.1105e+01],\n",
      "        [-4.7580e+00],\n",
      "        [-2.5052e+00],\n",
      "        [-4.5819e+00],\n",
      "        [-7.8860e+00],\n",
      "        [ 3.5865e+00],\n",
      "        [ 2.7281e+00],\n",
      "        [-2.4176e+00],\n",
      "        [-1.7376e+00],\n",
      "        [-2.9102e+00],\n",
      "        [-3.5574e-02],\n",
      "        [-1.0665e+00],\n",
      "        [-2.8413e+00],\n",
      "        [-3.3350e+00],\n",
      "        [ 3.5693e-01],\n",
      "        [ 2.3556e+00],\n",
      "        [ 1.9313e+00],\n",
      "        [ 2.9121e+00],\n",
      "        [-4.7180e+00],\n",
      "        [ 5.4234e+00],\n",
      "        [ 1.4749e+00],\n",
      "        [-2.1228e+00],\n",
      "        [-6.7856e+00],\n",
      "        [ 3.4134e+00],\n",
      "        [ 1.2026e+00],\n",
      "        [ 4.6026e+00],\n",
      "        [-7.2176e+00],\n",
      "        [ 5.6011e+00],\n",
      "        [-2.1635e+00],\n",
      "        [-1.8329e+00],\n",
      "        [-6.3989e-03],\n",
      "        [-6.0069e+00],\n",
      "        [ 2.7715e+00],\n",
      "        [ 4.3553e+00],\n",
      "        [ 5.6910e+00],\n",
      "        [ 2.4303e+00],\n",
      "        [-4.1399e+00],\n",
      "        [-4.8895e+00],\n",
      "        [-6.6656e+00],\n",
      "        [-1.0676e-01],\n",
      "        [-6.7854e-01],\n",
      "        [-1.7920e+00],\n",
      "        [ 3.5537e+00],\n",
      "        [-6.5446e-01],\n",
      "        [-8.7625e+00],\n",
      "        [ 1.6697e+00],\n",
      "        [-6.0959e+00],\n",
      "        [ 4.8477e+00],\n",
      "        [ 4.5954e+00],\n",
      "        [-4.7042e+00],\n",
      "        [-3.5600e+00],\n",
      "        [ 3.9640e+00],\n",
      "        [ 4.2807e+00],\n",
      "        [ 5.2725e+00],\n",
      "        [ 4.4089e+00],\n",
      "        [-4.9187e+00],\n",
      "        [-2.6507e+00],\n",
      "        [-1.8781e+00],\n",
      "        [-1.9223e+00],\n",
      "        [ 2.1609e+00],\n",
      "        [-7.1088e+00],\n",
      "        [-3.4003e+00],\n",
      "        [ 2.5492e+00],\n",
      "        [-2.6515e+00],\n",
      "        [-2.2531e-02],\n",
      "        [-1.7399e+00],\n",
      "        [-5.0383e+00],\n",
      "        [-1.5691e+00],\n",
      "        [ 1.5727e+00],\n",
      "        [ 7.2347e-01],\n",
      "        [-9.1853e+00],\n",
      "        [-2.6197e+00],\n",
      "        [ 3.7551e+00],\n",
      "        [-9.3342e-01],\n",
      "        [-7.7705e-01],\n",
      "        [ 5.0791e+00],\n",
      "        [-5.9401e+00],\n",
      "        [-5.1571e+00],\n",
      "        [-6.9760e+00],\n",
      "        [-4.4459e+00],\n",
      "        [-5.0397e+00],\n",
      "        [ 1.0101e+00],\n",
      "        [-1.2591e+00],\n",
      "        [ 2.4631e+00],\n",
      "        [-8.8719e-01],\n",
      "        [ 3.8947e+00],\n",
      "        [ 3.4246e+00],\n",
      "        [-3.3944e-01],\n",
      "        [ 5.0278e+00],\n",
      "        [-7.0088e+00],\n",
      "        [-6.1706e+00],\n",
      "        [ 5.8208e+00],\n",
      "        [-8.5734e-01],\n",
      "        [ 6.3306e+00],\n",
      "        [ 1.4105e+00],\n",
      "        [ 2.7959e+00],\n",
      "        [ 1.1177e+00],\n",
      "        [ 2.9624e+00],\n",
      "        [ 4.3390e+00],\n",
      "        [ 5.6974e+00],\n",
      "        [ 4.1952e+00],\n",
      "        [ 5.7542e+00],\n",
      "        [ 1.7112e+00],\n",
      "        [-1.4328e+01],\n",
      "        [-6.7181e+00],\n",
      "        [ 2.6704e+00],\n",
      "        [-6.3511e+00],\n",
      "        [-5.5403e+00],\n",
      "        [-7.9942e+00],\n",
      "        [ 3.7142e+00],\n",
      "        [ 1.3695e+00],\n",
      "        [-4.5780e+00],\n",
      "        [-6.7951e+00],\n",
      "        [ 1.2296e+00],\n",
      "        [-8.7427e+00],\n",
      "        [-5.0707e+00],\n",
      "        [ 4.9027e+00],\n",
      "        [-8.5261e-01],\n",
      "        [ 1.9617e+00],\n",
      "        [-6.5486e+00],\n",
      "        [ 2.4857e+00],\n",
      "        [ 6.0851e+00],\n",
      "        [ 3.4062e+00],\n",
      "        [ 5.5408e+00],\n",
      "        [-2.3331e+00],\n",
      "        [-3.7847e+00],\n",
      "        [ 4.7383e+00],\n",
      "        [ 4.0050e+00],\n",
      "        [-1.0185e+01],\n",
      "        [ 3.0388e-01],\n",
      "        [-1.9077e+00],\n",
      "        [-5.9544e+00],\n",
      "        [ 7.3700e-01],\n",
      "        [-5.0004e+00],\n",
      "        [-6.2550e+00],\n",
      "        [ 8.8510e-01],\n",
      "        [-6.3849e+00],\n",
      "        [-4.3459e+00],\n",
      "        [-7.5514e+00],\n",
      "        [ 3.4031e+00],\n",
      "        [-3.4205e+00],\n",
      "        [-8.1978e-01],\n",
      "        [-5.9469e+00],\n",
      "        [ 2.6412e+00],\n",
      "        [ 3.1505e+00],\n",
      "        [-4.5122e+00],\n",
      "        [-6.7732e+00],\n",
      "        [ 1.0485e+00],\n",
      "        [ 5.4856e+00],\n",
      "        [ 3.0354e+00],\n",
      "        [ 3.8301e+00],\n",
      "        [-4.8234e+00],\n",
      "        [ 2.7681e+00],\n",
      "        [-6.6516e+00],\n",
      "        [ 1.5527e+00],\n",
      "        [ 2.3131e+00],\n",
      "        [ 6.6138e+00],\n",
      "        [ 5.6959e-01],\n",
      "        [-1.2973e+01],\n",
      "        [-5.8005e+00],\n",
      "        [-5.1666e+00],\n",
      "        [ 3.8313e+00],\n",
      "        [-1.7254e+00],\n",
      "        [ 1.6845e+00],\n",
      "        [-2.0426e+00],\n",
      "        [-1.0808e+00],\n",
      "        [ 1.3272e+00],\n",
      "        [-7.8195e+00],\n",
      "        [-5.0301e+00],\n",
      "        [-1.7412e+00],\n",
      "        [ 1.0195e-01],\n",
      "        [-5.1911e+00],\n",
      "        [-2.5485e+00],\n",
      "        [-2.8253e+00],\n",
      "        [ 2.8007e+00],\n",
      "        [ 7.9335e-01],\n",
      "        [-5.9253e+00],\n",
      "        [ 5.4916e+00],\n",
      "        [-9.4363e+00],\n",
      "        [ 1.5037e+00],\n",
      "        [-1.4526e+00],\n",
      "        [-6.3885e+00],\n",
      "        [-5.1186e+00],\n",
      "        [-5.9507e+00],\n",
      "        [-1.1281e+00],\n",
      "        [ 3.2184e-01],\n",
      "        [ 4.0286e-01],\n",
      "        [-4.5722e+00],\n",
      "        [ 3.2822e+00],\n",
      "        [-1.5144e+00],\n",
      "        [ 4.1237e+00],\n",
      "        [-5.9124e+00],\n",
      "        [-5.4073e+00],\n",
      "        [ 8.5688e-01],\n",
      "        [ 4.4725e-01],\n",
      "        [-4.0651e+00],\n",
      "        [ 1.1110e+00],\n",
      "        [-1.6899e+00],\n",
      "        [-6.2279e+00],\n",
      "        [-8.7403e+00],\n",
      "        [-1.2112e+00],\n",
      "        [ 5.5753e+00],\n",
      "        [ 2.3353e+00],\n",
      "        [ 3.6766e+00],\n",
      "        [-4.0130e+00],\n",
      "        [-3.3347e+00],\n",
      "        [-4.9142e-01],\n",
      "        [ 5.8781e+00],\n",
      "        [ 5.9527e+00],\n",
      "        [ 6.2702e+00],\n",
      "        [-6.4941e+00],\n",
      "        [ 1.7619e+00],\n",
      "        [ 3.8237e+00],\n",
      "        [ 3.0533e+00],\n",
      "        [ 1.0444e+00],\n",
      "        [-3.0323e+00],\n",
      "        [ 3.1169e+00],\n",
      "        [ 1.0449e+00],\n",
      "        [-2.4887e-01],\n",
      "        [-1.1801e+00],\n",
      "        [ 3.4994e+00],\n",
      "        [ 1.8847e+00],\n",
      "        [ 2.3025e-01],\n",
      "        [-6.3632e+00],\n",
      "        [ 5.1770e+00],\n",
      "        [ 3.4903e+00],\n",
      "        [-3.4217e+00],\n",
      "        [-1.4640e+01],\n",
      "        [ 3.1811e+00],\n",
      "        [ 2.1257e+00],\n",
      "        [-6.3502e+00],\n",
      "        [ 2.7527e+00],\n",
      "        [-9.9097e+00],\n",
      "        [-1.1773e+00],\n",
      "        [ 5.0879e+00],\n",
      "        [-5.0962e+00],\n",
      "        [ 3.7399e+00],\n",
      "        [ 7.8207e-01],\n",
      "        [ 4.5521e+00],\n",
      "        [ 1.0064e+00],\n",
      "        [ 2.9786e-01],\n",
      "        [ 1.6805e+00],\n",
      "        [-7.4854e+00],\n",
      "        [ 3.4658e+00],\n",
      "        [-5.3574e+00],\n",
      "        [ 2.0862e+00],\n",
      "        [ 4.5250e+00],\n",
      "        [ 3.0169e+00],\n",
      "        [-3.6180e+00],\n",
      "        [ 5.3907e+00],\n",
      "        [ 2.7989e+00],\n",
      "        [-7.7052e+00],\n",
      "        [-6.3886e+00],\n",
      "        [ 4.0120e+00],\n",
      "        [-3.1339e+00],\n",
      "        [-1.5015e+00],\n",
      "        [ 3.4670e-01],\n",
      "        [-2.2834e+00],\n",
      "        [-5.7850e+00],\n",
      "        [-7.9989e+00],\n",
      "        [-8.4301e+00],\n",
      "        [-2.7347e+00],\n",
      "        [-5.3777e+00],\n",
      "        [-1.4272e+00],\n",
      "        [ 5.7248e+00],\n",
      "        [ 3.2913e+00],\n",
      "        [-5.5947e+00],\n",
      "        [ 4.5295e+00],\n",
      "        [ 4.6822e+00],\n",
      "        [ 3.2427e+00],\n",
      "        [-2.2845e+00],\n",
      "        [-6.8667e+00],\n",
      "        [-2.3498e-01],\n",
      "        [ 3.8807e+00],\n",
      "        [-4.3903e+00],\n",
      "        [ 3.2987e+00],\n",
      "        [-9.2758e+00],\n",
      "        [ 5.2994e+00],\n",
      "        [-4.4452e+00],\n",
      "        [ 3.4542e+00],\n",
      "        [ 5.3514e-01],\n",
      "        [-4.5821e+00],\n",
      "        [-5.4464e-02],\n",
      "        [ 1.6912e+00],\n",
      "        [-6.8336e+00],\n",
      "        [-2.7352e+00],\n",
      "        [ 5.6644e+00],\n",
      "        [-4.4975e+00],\n",
      "        [-6.0675e+00],\n",
      "        [-1.0388e+01],\n",
      "        [-8.2273e+00],\n",
      "        [-5.3026e+00],\n",
      "        [-6.9053e+00],\n",
      "        [-3.1498e+00],\n",
      "        [ 5.6127e+00],\n",
      "        [ 3.6839e+00],\n",
      "        [-9.1893e+00],\n",
      "        [ 2.3068e+00],\n",
      "        [-4.7529e-02],\n",
      "        [-4.5163e+00],\n",
      "        [ 3.2414e+00],\n",
      "        [ 2.0394e+00],\n",
      "        [ 2.9988e+00],\n",
      "        [-3.9522e+00],\n",
      "        [ 6.3718e-01],\n",
      "        [ 2.9959e+00],\n",
      "        [-5.7410e+00],\n",
      "        [ 6.5450e+00],\n",
      "        [ 9.4655e-01],\n",
      "        [-1.6304e+00],\n",
      "        [ 6.1183e-01],\n",
      "        [-9.3662e+00],\n",
      "        [-4.9358e+00],\n",
      "        [ 3.9936e+00],\n",
      "        [ 9.5382e-01],\n",
      "        [ 2.6211e+00],\n",
      "        [ 2.3720e+00],\n",
      "        [ 5.7435e+00],\n",
      "        [-2.9900e+00],\n",
      "        [ 1.7193e+00],\n",
      "        [-5.9155e+00],\n",
      "        [-6.0649e-01],\n",
      "        [-3.5820e+00],\n",
      "        [ 1.4313e+00],\n",
      "        [-1.2083e+01],\n",
      "        [-6.1561e+00],\n",
      "        [-4.1093e+00],\n",
      "        [-4.2912e+00],\n",
      "        [ 2.7350e+00],\n",
      "        [-2.3717e+00],\n",
      "        [ 2.3229e+00],\n",
      "        [ 4.8631e+00],\n",
      "        [ 1.6695e+00],\n",
      "        [-3.5077e+00],\n",
      "        [ 3.5526e+00],\n",
      "        [-5.5759e+00],\n",
      "        [ 1.3669e+00],\n",
      "        [-1.4475e+01],\n",
      "        [ 1.7562e+00],\n",
      "        [-5.2721e+00],\n",
      "        [-7.4934e+00],\n",
      "        [-3.4587e+00],\n",
      "        [ 4.7705e+00],\n",
      "        [ 2.8860e+00],\n",
      "        [-5.1443e+00],\n",
      "        [-1.7021e+00],\n",
      "        [-8.5172e+00],\n",
      "        [-1.7145e+00],\n",
      "        [-7.9809e-01],\n",
      "        [ 3.4653e+00],\n",
      "        [ 3.3165e+00],\n",
      "        [-6.6906e+00],\n",
      "        [-6.1284e+00],\n",
      "        [-4.6734e+00],\n",
      "        [-1.1155e-01],\n",
      "        [-5.7350e+00],\n",
      "        [-5.6207e+00],\n",
      "        [ 4.5352e+00],\n",
      "        [ 3.1225e+00],\n",
      "        [ 1.1771e+00],\n",
      "        [ 9.9686e-01],\n",
      "        [ 5.0197e+00],\n",
      "        [-1.5075e+00],\n",
      "        [ 3.0576e+00],\n",
      "        [ 3.6164e+00],\n",
      "        [-7.4094e+00],\n",
      "        [ 2.1685e+00],\n",
      "        [-3.0001e+00],\n",
      "        [ 5.9294e+00],\n",
      "        [ 5.1117e+00],\n",
      "        [ 6.0284e+00],\n",
      "        [ 4.0424e+00],\n",
      "        [-5.7160e+00],\n",
      "        [-7.1424e-01],\n",
      "        [ 1.8996e+00],\n",
      "        [-1.2609e+00],\n",
      "        [-4.5825e+00],\n",
      "        [ 4.8942e+00],\n",
      "        [ 4.0095e+00],\n",
      "        [ 1.1474e+00],\n",
      "        [-7.1068e+00],\n",
      "        [ 2.5391e+00],\n",
      "        [ 1.5835e-01],\n",
      "        [ 4.8692e+00],\n",
      "        [-1.2652e+00],\n",
      "        [ 4.4485e+00],\n",
      "        [ 5.0052e+00],\n",
      "        [ 3.2299e+00],\n",
      "        [ 7.4338e-01],\n",
      "        [-4.3606e+00],\n",
      "        [ 3.8241e+00],\n",
      "        [-1.6651e+00],\n",
      "        [ 1.4718e+00],\n",
      "        [ 4.4962e+00],\n",
      "        [ 4.3936e-02],\n",
      "        [ 4.6639e+00],\n",
      "        [-4.0641e+00],\n",
      "        [ 5.7702e+00],\n",
      "        [ 5.3460e-01],\n",
      "        [-7.8764e+00],\n",
      "        [ 3.6352e+00],\n",
      "        [ 2.0455e+00],\n",
      "        [-5.5492e+00],\n",
      "        [ 4.5601e+00],\n",
      "        [ 6.1020e+00],\n",
      "        [-2.1039e+00],\n",
      "        [-2.5562e+00],\n",
      "        [-3.5667e+00],\n",
      "        [ 2.7251e+00],\n",
      "        [ 1.4552e+00],\n",
      "        [-3.6708e+00],\n",
      "        [ 2.8821e+00],\n",
      "        [-5.8237e-01],\n",
      "        [-9.1314e+00],\n",
      "        [-4.5616e+00],\n",
      "        [-8.1175e+00],\n",
      "        [ 4.5925e-01],\n",
      "        [ 1.4037e+00],\n",
      "        [ 2.4291e+00],\n",
      "        [-4.8503e+00],\n",
      "        [-4.6949e+00],\n",
      "        [ 3.0804e+00],\n",
      "        [ 4.9345e+00],\n",
      "        [-6.9370e+00],\n",
      "        [-8.2027e+00],\n",
      "        [ 3.0172e+00],\n",
      "        [-7.2703e+00],\n",
      "        [ 1.4254e+00],\n",
      "        [ 6.2304e+00],\n",
      "        [-1.8118e+00],\n",
      "        [-4.6258e+00],\n",
      "        [-4.7624e+00],\n",
      "        [-2.1239e+00],\n",
      "        [ 5.1415e+00],\n",
      "        [-5.1656e+00],\n",
      "        [ 5.2037e+00],\n",
      "        [ 4.9270e+00],\n",
      "        [ 2.2407e+00],\n",
      "        [-1.6330e+00],\n",
      "        [-2.2416e+00],\n",
      "        [ 6.0350e+00],\n",
      "        [ 3.0252e+00],\n",
      "        [-1.1061e+01],\n",
      "        [ 7.7551e-01],\n",
      "        [ 4.4500e+00],\n",
      "        [ 2.0172e+00],\n",
      "        [ 1.4915e+00],\n",
      "        [-4.1186e+00],\n",
      "        [-5.2292e+00],\n",
      "        [ 4.2201e+00],\n",
      "        [-5.9758e+00],\n",
      "        [ 3.3506e+00],\n",
      "        [-4.8657e+00],\n",
      "        [-8.8389e+00],\n",
      "        [-7.1257e+00],\n",
      "        [-6.4957e+00],\n",
      "        [ 2.0560e+00],\n",
      "        [ 1.2653e+00],\n",
      "        [ 3.0103e+00],\n",
      "        [-6.6488e+00],\n",
      "        [-3.9023e+00],\n",
      "        [ 3.0913e+00],\n",
      "        [-7.2994e+00],\n",
      "        [ 5.7032e+00],\n",
      "        [-1.8219e+00],\n",
      "        [-2.9697e+00],\n",
      "        [-5.8781e+00],\n",
      "        [-1.8177e+00],\n",
      "        [-6.3114e+00],\n",
      "        [-2.6133e+00],\n",
      "        [-3.7909e+00],\n",
      "        [ 3.7880e+00],\n",
      "        [ 3.0504e+00],\n",
      "        [-5.8023e+00],\n",
      "        [ 5.4107e+00],\n",
      "        [-3.3588e+00],\n",
      "        [-5.5234e+00],\n",
      "        [ 2.0998e+00],\n",
      "        [ 5.1153e+00],\n",
      "        [-3.0215e+00],\n",
      "        [-1.8996e+00],\n",
      "        [ 4.4464e+00],\n",
      "        [ 6.8406e+00],\n",
      "        [ 2.2179e+00],\n",
      "        [ 2.1110e+00],\n",
      "        [-1.6928e+00],\n",
      "        [-4.2341e+00],\n",
      "        [-5.5778e+00],\n",
      "        [ 3.8825e-01],\n",
      "        [-1.7698e+00],\n",
      "        [ 1.5904e+00],\n",
      "        [-1.8205e+00],\n",
      "        [-1.5722e+00],\n",
      "        [-1.9269e+00],\n",
      "        [-4.9505e-01],\n",
      "        [ 2.6428e+00],\n",
      "        [-9.4432e-01],\n",
      "        [-6.4291e+00],\n",
      "        [-3.5542e+00],\n",
      "        [ 2.6739e+00],\n",
      "        [-8.3433e+00],\n",
      "        [ 5.6440e+00],\n",
      "        [ 1.4418e+00],\n",
      "        [ 3.7259e+00],\n",
      "        [ 1.0598e+00],\n",
      "        [-4.4492e+00],\n",
      "        [ 3.4378e+00],\n",
      "        [ 3.1739e+00],\n",
      "        [ 2.4320e+00],\n",
      "        [-5.2176e+00],\n",
      "        [ 4.0356e+00],\n",
      "        [-6.9033e+00],\n",
      "        [ 1.3568e+00],\n",
      "        [-8.0337e+00],\n",
      "        [-1.8190e+00],\n",
      "        [ 6.5546e+00],\n",
      "        [-4.4197e+00],\n",
      "        [-2.2792e+00],\n",
      "        [ 2.0998e+00],\n",
      "        [ 1.0821e+00],\n",
      "        [-4.6414e+00],\n",
      "        [ 5.1889e+00],\n",
      "        [ 2.5056e+00],\n",
      "        [ 1.7929e-01],\n",
      "        [ 1.7760e+00],\n",
      "        [ 1.2550e+00],\n",
      "        [-2.1431e+00],\n",
      "        [-5.3426e-01],\n",
      "        [ 2.1312e-01],\n",
      "        [ 2.6153e+00],\n",
      "        [-4.3095e+00],\n",
      "        [-7.1443e+00],\n",
      "        [-7.9421e+00],\n",
      "        [ 8.5310e-01],\n",
      "        [ 4.8357e+00],\n",
      "        [ 3.4990e+00],\n",
      "        [ 3.3312e+00],\n",
      "        [-1.9828e+00],\n",
      "        [-4.5982e+00],\n",
      "        [-5.2757e+00],\n",
      "        [-6.4825e+00],\n",
      "        [-7.7000e+00],\n",
      "        [ 3.3020e+00],\n",
      "        [-7.6250e-01],\n",
      "        [ 1.6487e+00],\n",
      "        [-6.2907e+00],\n",
      "        [-5.3439e+00],\n",
      "        [ 4.6869e+00],\n",
      "        [ 4.3215e+00],\n",
      "        [ 1.8729e-01],\n",
      "        [-8.2834e+00],\n",
      "        [-4.0178e+00],\n",
      "        [ 4.3837e+00],\n",
      "        [ 1.7540e+00],\n",
      "        [ 5.2083e+00],\n",
      "        [-7.9731e+00],\n",
      "        [-2.5955e+00],\n",
      "        [-3.6691e+00],\n",
      "        [-1.8445e+00],\n",
      "        [ 2.7530e+00],\n",
      "        [-1.1033e+01],\n",
      "        [-9.0110e+00],\n",
      "        [ 3.6730e+00],\n",
      "        [-3.5542e+00],\n",
      "        [ 1.0629e+00],\n",
      "        [ 3.3096e+00],\n",
      "        [ 7.9133e+00],\n",
      "        [-9.5842e+00],\n",
      "        [ 2.8793e+00],\n",
      "        [ 6.1559e-01],\n",
      "        [ 4.6078e+00],\n",
      "        [ 2.0630e+00],\n",
      "        [ 6.0370e+00],\n",
      "        [ 2.7288e+00],\n",
      "        [-6.0204e+00],\n",
      "        [-8.7932e+00],\n",
      "        [-2.0078e+00],\n",
      "        [-4.0242e+00],\n",
      "        [ 5.3101e+00],\n",
      "        [-6.1791e+00],\n",
      "        [-3.3323e+00],\n",
      "        [-7.9674e+00],\n",
      "        [ 1.3397e+00],\n",
      "        [-7.8074e+00],\n",
      "        [-6.1495e+00],\n",
      "        [ 7.1995e-01],\n",
      "        [ 3.8156e+00],\n",
      "        [-3.9477e+00],\n",
      "        [ 2.0785e+00],\n",
      "        [-1.5800e-01],\n",
      "        [ 2.9995e+00],\n",
      "        [ 2.4644e+00],\n",
      "        [-6.2778e+00],\n",
      "        [ 1.4050e+00],\n",
      "        [ 1.7786e+00],\n",
      "        [ 4.9459e+00],\n",
      "        [ 5.1391e+00],\n",
      "        [ 4.1833e+00],\n",
      "        [-1.7865e+00],\n",
      "        [ 7.9216e-01],\n",
      "        [-2.5218e+00],\n",
      "        [ 5.8154e+00],\n",
      "        [-7.6369e+00],\n",
      "        [ 1.2106e+00],\n",
      "        [-1.7192e+00],\n",
      "        [-3.3291e+00],\n",
      "        [-7.0071e+00],\n",
      "        [-6.7583e+00],\n",
      "        [ 4.4626e+00],\n",
      "        [-7.8512e+00],\n",
      "        [-1.5327e+00],\n",
      "        [-3.8863e+00],\n",
      "        [-5.7647e+00],\n",
      "        [-2.2679e+00],\n",
      "        [-1.0221e+01],\n",
      "        [ 4.2104e+00],\n",
      "        [-7.9724e+00],\n",
      "        [ 2.9372e-01],\n",
      "        [ 2.2140e+00],\n",
      "        [-5.4875e+00],\n",
      "        [ 1.6462e+00],\n",
      "        [-6.3126e+00],\n",
      "        [-6.6363e-01],\n",
      "        [-1.4253e+00],\n",
      "        [-6.2307e+00],\n",
      "        [-3.2719e+00],\n",
      "        [ 2.5503e-01],\n",
      "        [-9.6439e+00],\n",
      "        [-4.7645e+00],\n",
      "        [ 1.9107e+00],\n",
      "        [-3.0160e+00],\n",
      "        [-3.4642e+00],\n",
      "        [-8.3601e-01],\n",
      "        [-5.5416e+00],\n",
      "        [-3.4916e+00],\n",
      "        [ 3.8714e+00],\n",
      "        [ 5.2156e+00],\n",
      "        [ 2.4577e+00],\n",
      "        [-6.7974e+00],\n",
      "        [ 5.6847e+00],\n",
      "        [ 4.6782e+00],\n",
      "        [ 2.4591e+00],\n",
      "        [-2.7954e+00],\n",
      "        [ 6.9358e-01],\n",
      "        [-7.1530e+00],\n",
      "        [ 1.5303e-01],\n",
      "        [-4.3339e+00],\n",
      "        [ 4.7680e+00],\n",
      "        [ 3.0765e+00],\n",
      "        [-2.2898e+00],\n",
      "        [ 2.8250e+00],\n",
      "        [-3.3049e+00],\n",
      "        [ 2.7185e+00],\n",
      "        [-6.1926e+00],\n",
      "        [-1.9517e+00],\n",
      "        [ 2.3538e+00],\n",
      "        [ 3.2238e+00],\n",
      "        [-1.0470e+01],\n",
      "        [ 5.3659e+00],\n",
      "        [ 6.7107e+00],\n",
      "        [ 1.5593e+00],\n",
      "        [-7.4786e+00],\n",
      "        [ 4.8698e+00],\n",
      "        [-1.0274e+01],\n",
      "        [-1.0712e+00],\n",
      "        [ 1.5310e+00],\n",
      "        [ 2.3114e-01],\n",
      "        [ 4.7001e+00],\n",
      "        [-5.4303e+00],\n",
      "        [-2.0958e+00],\n",
      "        [ 5.1904e-01],\n",
      "        [ 3.8306e+00],\n",
      "        [ 6.9110e+00],\n",
      "        [-5.6368e-01],\n",
      "        [ 1.8479e+00],\n",
      "        [-2.9359e+00],\n",
      "        [ 3.3983e+00],\n",
      "        [-3.2559e+00],\n",
      "        [ 2.4837e+00],\n",
      "        [-8.4596e+00],\n",
      "        [ 1.4566e+00],\n",
      "        [ 4.4396e+00],\n",
      "        [ 2.5875e+00],\n",
      "        [ 3.6857e+00],\n",
      "        [ 3.5660e+00],\n",
      "        [-4.7408e+00],\n",
      "        [ 1.0588e+00],\n",
      "        [ 2.7712e+00],\n",
      "        [ 5.8418e-01],\n",
      "        [-1.1396e+01],\n",
      "        [ 5.5647e+00],\n",
      "        [-1.1517e+01],\n",
      "        [-9.8506e+00],\n",
      "        [-2.7966e+00],\n",
      "        [-5.6448e+00],\n",
      "        [ 1.3642e+00],\n",
      "        [ 6.1292e+00],\n",
      "        [ 5.1531e+00],\n",
      "        [ 1.9749e+00],\n",
      "        [ 5.1263e+00],\n",
      "        [-2.3684e+00],\n",
      "        [-7.1648e+00],\n",
      "        [ 4.2639e+00],\n",
      "        [-3.2052e-01],\n",
      "        [ 6.9100e-01],\n",
      "        [-2.5793e+00],\n",
      "        [-6.8011e+00],\n",
      "        [ 3.0643e+00],\n",
      "        [-8.3341e+00],\n",
      "        [-9.6250e+00],\n",
      "        [ 1.5748e+00],\n",
      "        [-5.1595e+00],\n",
      "        [ 1.4749e+00],\n",
      "        [-4.6547e+00]], grad_fn=<AddmmBackward0>)\n",
      "tensor([1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
      "        1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
      "        0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
      "        0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
      "        0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
      "        1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
      "        0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
      "        1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1.,\n",
      "        0., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.,\n",
      "        0., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
      "        1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1.,\n",
      "        1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
      "        1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
      "        1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
      "        0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.,\n",
      "        1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 1.,\n",
      "        1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
      "        0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
      "        0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
      "        1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
      "        0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
      "        1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
      "        1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
      "        0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
      "        1., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "model = model.to('cpu')\n",
    "X,y = next(iter(test_loader))\n",
    "yHat = model(X)\n",
    "\n",
    "# check size of output\n",
    "print('\\nOutput size:')\n",
    "print(yHat)\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de6fc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3db60e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9402)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = torch.mean(((yHat.squeeze()>0).float() == y).float())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf2c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9384436701509872\n"
     ]
    }
   ],
   "source": [
    "# evaluate your model\n",
    "from sklearn.metrics import f1_score\n",
    "print(f1_score(y.detach().numpy(),yHat.detach().numpy()>0,average='binary'))\n",
    "# To-Do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa321fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "del yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1259be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To-Do\n",
    "# test_set = pd.read_csv('../data/test.csv')\n",
    "# testT = np.array(test_set,dtype=np.float32)\n",
    "# testT = torch.tensor(testT).to(device)\n",
    "# yHatt = torch.argmax(bestModel(testT),axis=1)\n",
    "# yHatt = yHatt.to('cpu')\n",
    "# predict = []\n",
    "# for i in yHatt:\n",
    "#     predict.append(allAuthor[i])\n",
    "# submission = pd.DataFrame(predict,columns=['author'])\n",
    "# submission =\n",
    "pat = 'test_images\\\\'\n",
    "names = []\n",
    "imagess=[]\n",
    "for subdir, dirs, files in os.walk(pat):\n",
    "    for file in files:\n",
    "        im =cv2.imread(pat+file)\n",
    "        imagess.append(transform(im))\n",
    "        names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8be7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesT = torch.stack(imagess, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2faf87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yHat = model(imagesT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c2b9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = (yHat.squeeze()>0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5570bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1572])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66cdb6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=answer.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf2b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'file_name': names,'hamiltonian':answer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07b6eac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>hamiltonian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>graph1000.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graph1001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graph1004.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>graph1008.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>graph1009.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>graph987.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>graph989.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>graph991.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>graph996.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>graph998.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1572 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name  hamiltonian\n",
       "0     graph1000.png            0\n",
       "1     graph1001.png            0\n",
       "2     graph1004.png            0\n",
       "3     graph1008.png            0\n",
       "4     graph1009.png            1\n",
       "...             ...          ...\n",
       "1567   graph987.png            0\n",
       "1568   graph989.png            1\n",
       "1569   graph991.png            0\n",
       "1570   graph996.png            0\n",
       "1571   graph998.png            1\n",
       "\n",
       "[1572 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cceb36a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['hamiltonian_graph.ipynb', 'submission.csv']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "#if not os.path.exists(os.path.join(os.getcwd(), 'Student_GPA.ipynb')):\n",
    " #   %notebook -e hamiltonian_graph.ipynb\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['hamiltonian_graph.ipynb', 'submission.csv']\n",
    "compress(file_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
